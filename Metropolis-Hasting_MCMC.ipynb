{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metropolis Hasting MCMC\n",
    "\n",
    "The **Metropolis-Hastings algorithm**, a Markov chain Monte Carlo (MCMC) method, is used in statistics and statistical physics to generate a series of random samples from a probability distribution for which direct sampling is difficult. These samples are used to approximate the distribution and enabling tasks such as computing integrals (e.g. expected values). This algorithm is particularly useful in high dimensions. \n",
    "\n",
    "In this notebook we will focus on a 2-dimensional target distributions as we want to be able to illustrate how the algorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from functools import partial\n",
    "import requests\n",
    "\n",
    "#from Target import *\n",
    "#from Animation_MH import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = 'https://raw.githubusercontent.com/ValentinKil/MCMC/main/Target.py'\n",
    "Target = requests.get(github_url).text\n",
    "exec(Target)\n",
    "github_url = 'https://raw.githubusercontent.com/ValentinKil/MCMC/main/Animation_MH.py'\n",
    "Animation_MH = requests.get(github_url).text\n",
    "exec(Animation_MH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Distributions \n",
    "\n",
    "Here we will focus on two relatively simple target distributions that can be find in **Target.py**. A Gaussian mixture whose modes are not too far apart **gausmix** and a ring-shaped distribution **ring**. \n",
    "\n",
    "### Gaussian mixture\n",
    "\n",
    "For the mixture of Gaussian, we chose to sum 3 Gaussian distribution of dimension 2. The probability density at a point $x$ is given by:\n",
    "\n",
    "$$\n",
    "\\pi(x) = \\frac{1}{3} \\left[ \n",
    "\\mathcal{N}(x | \\mu_1, \\Sigma_1) + \n",
    "\\mathcal{N}(x | \\mu_2, \\Sigma_2) + \n",
    "\\mathcal{N}(x | \\mu_3, \\Sigma_3) \n",
    "\\right]\n",
    "$$\n",
    "\n",
    "where $\\mathcal{N}(x | \\mu_i, \\Sigma_i)$ represents the probability density function of a Gaussian distribution with mean $\\mu_i$ and covariance matrix $\\Sigma_i$ for the $i$^{th} component of the mixture with : \n",
    "\n",
    "$$\n",
    "\\mu_1 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix};~~~~~\\mu_2 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix};~~~~~\\mu_3 = \\begin{pmatrix} 3 \\\\ 2 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "and : \n",
    "\n",
    "$$\n",
    "\\Sigma_1 = \\Sigma_3 =\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix};~~~~~\\Sigma_2 = \\begin{pmatrix} 2 & 0.5 \\\\ 0.5 & 2 \\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the gaussian mixture target \n",
    "X, Y = np.mgrid[-3:6:.05, -3:6:.05]\n",
    "pos = np.dstack((X, Y))\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax2.pcolormesh(X, Y, gausmix(pos),cmap='Blues',alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring-shaped distribution\n",
    "\n",
    "The second target distribution we will focus on is a ring-shaped distribution. This distribution mimics, in 2 dimensions, the behaviour of a simple Gaussian in very high dimension, indeed, in high dimension, the mass of a Gaussian concentrated in a ring, called the typical set. The probability density at a point $x$ is given by:\n",
    "\n",
    "$$\n",
    "\\pi(x)= \\exp\\left(-\\frac{1}{2} \\left(\\sqrt{x_1^2 + x_2^2} - 3\\right)^2\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the ring target \n",
    "X, Y = np.mgrid[-6:6:.05, -6:6:.05]\n",
    "pos = np.dstack((X, Y))\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax2.pcolormesh(X, Y, ring(pos),cmap='Blues',alpha=0.8)\n",
    "plt.axis('square') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Hasting Sampler\n",
    "\n",
    "We now want to implement a Metropolis Hasting Sampler following the algorithm explained in the lecture note. To use the animation functions provided below, the algorithm should return an np.array **sample** of size (n_iter,3), where n_iter is the number of samples we want to get. For each $i\\in[[ 1,n\\_iter]]$, we should let **sample[i,0:2]** be the new state proposed by the proposal distribution, and **sample[i,2]** should be True if the new state is accepted and False otherwise. The function should be general enough to accept any distribution target and any proposal/update rule.\n",
    "\n",
    "### Implementation of the sampler\n",
    "Please write your function here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MH_sampler(target,proposal,update_rule,init_state,n_iter):\n",
    "    \"\"\"Run the Metropolis-Hastings algorithm for n_iter iterations.\"\"\"\n",
    "    return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the Markov Chain\n",
    "\n",
    "We want to display the MCMC method nicely, the functions can be find in **Animation_MH.py**, they takes some time and probably deserve some improvement but gives good animations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different proposals \n",
    "\n",
    "As mentioned in the lecture notes, many different proposals can be used for Metropolis Hasting, here we focus on Random Walk and Langevin Algorithm.\n",
    "\n",
    "## Random Walk Metropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RW_update_rule(curr_state,var):\n",
    "\n",
    "def RW_proposal(curr_state,new_state):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian mixture\n",
    "\n",
    "Let us start by displaying the method for our Gaussian mixture distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose parameters\n",
    "var=2.8\n",
    "initialPoint=np.array([3,2])\n",
    "n_iter=10000\n",
    "\n",
    "\n",
    "#Sampling \n",
    "partial_RW_update_rule= partial(RW_update_rule,var=var)\n",
    "\n",
    "sample = MH_sampler(gausmix,RW_proposal,partial_RW_update_rule,initialPoint,n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animation\n",
    "\n",
    "xmin,xmax=-3,6\n",
    "ymin,ymax=-3,6\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "background_plot(ax,target=gausmix,xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax) # Add the background figure\n",
    "\n",
    "particle = ax.scatter([], [], c='black',s=10, marker='o', alpha=1)  # Initial position with higher alpha\n",
    "trail = ax.scatter([], [], c='black',s=10, marker='o', alpha=0.5)  # Particle trail with lower alpha\n",
    "line, = ax.plot([], [], c='black', alpha=0.5)  # Line connecting current and previous positions\n",
    "\n",
    "partial_init=partial(init,xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax,particle=particle,trail=trail,ax=ax,square=False)\n",
    "\n",
    "# Create the animation\n",
    "partial_update= partial(update,sample=sample,particle=particle,line=line,trail=trail)\n",
    "ani = FuncAnimation(fig, partial_update, frames=200, init_func=partial_init, blit=True)\n",
    "\n",
    "# Display the animation in the notebook\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb for choosing the step size **var** is to tune it to give an acceptance probability somewhere between 0.2 and 0.4. We can check this by approximating this probability using the Monte Carlo method over an excursion of the Markov chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_prob=np.cumsum(sample[:,2])[-1]/n_iter\n",
    "print(acceptance_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it's difficult to see from the animation that the MH algorithm gives a good approximation of the target distribution. To illustrate this, we can plot the running average $\\bar{X}_n=\\frac{1}{n}\\sum_{i=1}^nX_i$, where $X_i$ are the successive values returned by the algorithm. After enough MCMC iterations, this set should converge to the expected value of the target distribution.  To improve performance, we can forget about the first steps, waiting for the chain to reach the typical set where the mass is concentrated, that's the role of **burnin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter=10000\n",
    "sample1 = MH_sampler(gausmix,RW_proposal,partial_RW_update_rule,initialPoint,n_iter)\n",
    "sample2 = MH_sampler(gausmix,RW_proposal,partial_RW_update_rule,initialPoint,n_iter)\n",
    "sample3 = MH_sampler(gausmix,RW_proposal,partial_RW_update_rule,initialPoint,n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin=1000\n",
    "\n",
    "# Compute cumulative averages after burnin\n",
    "Avgs = [calculate_cumulative_average(sample[burnin:]) for sample in [sample1, sample2, sample3]]\n",
    "\n",
    "nb_gaussian = len(moy_list)\n",
    "Truemean = np.cumsum(moy_list, axis=0)[-1] / nb_gaussian\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns setup\n",
    "\n",
    "for i in range(2):  # Assuming two parameters for simplicity\n",
    "    for Avg in Avgs:\n",
    "        axs[i].plot(Avg[:, i])\n",
    "    axs[i].axhline(Truemean[i], color='r', label=f\"true $\\\\mu_{i+1}$\")\n",
    "    axs[i].set_title(f'MCMC trace plot for $\\\\mu_{i+1}$')\n",
    "    axs[i].set_xlabel('MCMC iterations')\n",
    "    axs[i].set_ylabel(f'$\\\\mu_{i+1}$')\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring-shaped distribution \n",
    "\n",
    "Then with the ring distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose parameters \n",
    "var=3.2\n",
    "initialPoint=np.array([-3,0])\n",
    "n_iter=10000\n",
    "\n",
    "\n",
    "#Sampling\n",
    "partial_RW_update_rule= partial(RW_update_rule,var=var)\n",
    "\n",
    "sample = MH_sampler(ring,RW_proposal,partial_RW_update_rule,initialPoint,n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animation\n",
    "\n",
    "xmin=center[0]-2*radius\n",
    "xmax=center[0]+2*radius\n",
    "ymin=center[1]-2*radius\n",
    "ymax=center[1]+2*radius\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "background_plot(ax,target=ring,xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax) # Add the background figure\n",
    "\n",
    "particle = ax.scatter([], [], c='black',s=10, marker='o', alpha=1)  # Initial position with higher alpha\n",
    "trail = ax.scatter([], [], c='black',s=10, marker='o', alpha=0.5)  # Particle trail with lower alpha\n",
    "line, = ax.plot([], [], c='black', alpha=0.5)  # Line connecting current and previous positions\n",
    "\n",
    "partial_init=partial(init,xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax,particle=particle,trail=trail,ax=ax,square=True)\n",
    "\n",
    "# Create the animation\n",
    "partial_update= partial(update,sample=sample,particle=particle,line=line,trail=trail)\n",
    "ani = FuncAnimation(fig, partial_update, frames=200, init_func=partial_init, blit=True)\n",
    "\n",
    "# Display the animation in the notebook\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_prob=np.cumsum(sample[:,2])[-1]/n_iter\n",
    "print(acceptance_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter=20000\n",
    "sample1 = MH_sampler(ring,RW_proposal,partial_RW_update_rule,initialPoint,n_iter)\n",
    "sample2 = MH_sampler(ring,RW_proposal,partial_RW_update_rule,initialPoint,n_iter)\n",
    "sample3 = MH_sampler(ring,RW_proposal,partial_RW_update_rule,initialPoint,n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin=1000\n",
    "\n",
    "# Compute cumulative averages after burnin\n",
    "Avgs = [calculate_cumulative_average(sample[burnin:]) for sample in [sample1, sample2, sample3]]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns setup\n",
    "\n",
    "for i in range(2):  # Assuming two parameters for simplicity\n",
    "    for Avg in Avgs:\n",
    "        axs[i].plot(Avg[:, i])\n",
    "    axs[i].axhline(center[i], color='r', label=f\"true $\\\\mu_{i+1}$\")\n",
    "    axs[i].set_title(f'MCMC trace plot for $\\\\mu_{i+1}$')\n",
    "    axs[i].set_xlabel('MCMC iterations')\n",
    "    axs[i].set_ylabel(f'$\\\\mu_{i+1}$')\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-adjusted Langevin Algorithm\n",
    "\n",
    "For MALA we need to compute the gradient of the log proposal. For our to target they can be found in **Target.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MALA_update_rule(curr_state,delta_log,sigma):\n",
    "\n",
    "def MALA_proposal(curr_state,new_state,delta_log,sigma):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian mixture\n",
    "\n",
    "Lets first try with the Gaussian mixture target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose paramters \n",
    "sigma=3\n",
    "initialPoint=np.array([0,0])\n",
    "n_iter=10000\n",
    "\n",
    "#Sampling\n",
    "partial_MALA_proposal= partial(MALA_proposal,delta_log=delta_log_gauss,sigma=sigma)\n",
    "partial_MALA_update_rule= partial(MALA_update_rule,delta_log=delta_log_gauss,sigma=sigma)\n",
    "\n",
    "sample = MH_sampler(gausmix,partial_MALA_proposal,partial_MALA_update_rule,initialPoint,n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animation\n",
    "\n",
    "xmin,xmax=-3,6\n",
    "ymin,ymax=-3,6\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "background_plot(ax,target=gausmix,xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax) # Add the background figure\n",
    "\n",
    "particle = ax.scatter([], [], c='black',s=10, marker='o', alpha=1)  # Initial position with higher alpha\n",
    "trail = ax.scatter([], [], c='black',s=10, marker='o', alpha=0.5)  # Particle trail with lower alpha\n",
    "line, = ax.plot([], [], c='black', alpha=0.5)  # Line connecting current and previous positions\n",
    "\n",
    "partial_init=partial(init,xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax,particle=particle,trail=trail,ax=ax,square=False)\n",
    "\n",
    "# Create the animation\n",
    "partial_update= partial(update,sample=sample,particle=particle,line=line,trail=trail)\n",
    "ani = FuncAnimation(fig, partial_update, frames=200, init_func=partial_init, blit=True)\n",
    "\n",
    "# Display the animation in the notebook\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb for choosing  **delta** is to tune it to give an acceptance probability somewhere between 0.4 and 0.6. We can check this by approximating this probability using the Monte Carlo method over an excursion of the Markov chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_prob=np.cumsum(sample[:,2])[-1]/n_iter\n",
    "print(acceptance_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter=10000\n",
    "sample1 = MH_sampler(gausmix,partial_MALA_proposal,partial_MALA_update_rule,initialPoint,n_iter)\n",
    "sample2 = MH_sampler(gausmix,partial_MALA_proposal,partial_MALA_update_rule,initialPoint,n_iter)\n",
    "sample3 = MH_sampler(gausmix,partial_MALA_proposal,partial_MALA_update_rule,initialPoint,n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin=2000\n",
    "\n",
    "# Compute cumulative averages after burnin\n",
    "Avgs = [calculate_cumulative_average(sample[burnin:]) for sample in [sample1, sample2, sample3]]\n",
    "\n",
    "nb_gaussian = len(moy_list)\n",
    "Truemean = np.cumsum(moy_list, axis=0)[-1] / nb_gaussian\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns setup\n",
    "\n",
    "for i in range(2):  # Assuming two parameters for simplicity\n",
    "    for Avg in Avgs:\n",
    "        axs[i].plot(Avg[:, i])\n",
    "    axs[i].axhline(Truemean[i], color='r', label=f\"true $\\\\mu_{i+1}$\")\n",
    "    axs[i].set_title(f'MCMC trace plot for $\\\\mu_{i+1}$')\n",
    "    axs[i].set_xlabel('MCMC iterations')\n",
    "    axs[i].set_ylabel(f'$\\\\mu_{i+1}$')\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring-shaped distribution \n",
    "And then for the ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose parameters \n",
    "sigma=3.5\n",
    "initialPoint=np.array([-3,0])\n",
    "n_iter=10000\n",
    "\n",
    "#Sampling\n",
    "\n",
    "partial_MALA_proposal= partial(MALA_proposal,delta_log=delta_log_ring,sigma=sigma)\n",
    "partial_MALA_update_rule= partial(MALA_update_rule,delta_log=delta_log_ring,sigma=sigma)\n",
    "\n",
    "sample = MH_sampler(ring,partial_MALA_proposal,partial_MALA_update_rule,initialPoint,n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animation\n",
    "xmin=center[0]-2*radius\n",
    "xmax=center[0]+2*radius\n",
    "ymin=center[1]-2*radius\n",
    "ymax=center[1]+2*radius\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "background_plot(ax,target=ring,xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax) # Add the background figure\n",
    "\n",
    "particle = ax.scatter([], [], c='black',s=10, marker='o', alpha=1)  # Initial position with higher alpha\n",
    "trail = ax.scatter([], [], c='black',s=10, marker='o', alpha=0.5)  # Particle trail with lower alpha\n",
    "line, = ax.plot([], [], c='black', alpha=0.5)  # Line connecting current and previous positions\n",
    "\n",
    "partial_init=partial(init,xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax,particle=particle,ax=ax,trail=trail,square=True)\n",
    "\n",
    "# Create the animation\n",
    "partial_update= partial(update,sample=sample,particle=particle,line=line,trail=trail)\n",
    "ani = FuncAnimation(fig, partial_update, frames=200, init_func=partial_init, blit=True)\n",
    "\n",
    "# Display the animation in the notebook\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_prob=np.cumsum(sample[:,2])[-1]/n_iter\n",
    "print(acceptance_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter=20000\n",
    "sample1 = MH_sampler(ring,partial_MALA_proposal,partial_MALA_update_rule,initialPoint,n_iter)\n",
    "sample2 = MH_sampler(ring,partial_MALA_proposal,partial_MALA_update_rule,initialPoint,n_iter)\n",
    "sample3 = MH_sampler(ring,partial_MALA_proposal,partial_MALA_update_rule,initialPoint,n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin=1000\n",
    "\n",
    "# Compute cumulative averages after burnin\n",
    "Avgs = [calculate_cumulative_average(sample[burnin:]) for sample in [sample1, sample2, sample3]]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns setup\n",
    "\n",
    "for i in range(2):  # Assuming two parameters for simplicity\n",
    "    for Avg in Avgs:\n",
    "        axs[i].plot(Avg[:, i])\n",
    "    axs[i].axhline(center[i], color='r', label=f\"true $\\\\mu_{i+1}$\")\n",
    "    axs[i].set_title(f'MCMC trace plot for $\\\\mu_{i+1}$')\n",
    "    axs[i].set_xlabel('MCMC iterations')\n",
    "    axs[i].set_ylabel(f'$\\\\mu_{i+1}$')\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
